{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\savan\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts fonttools.exe, pyftmerge.exe, pyftsubset.exe and ttx.exe are installed in 'c:\\Users\\savan\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script virtualenv.exe is installed in 'c:\\Users\\savan\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts pipenv-resolver.exe and pipenv.exe are installed in 'c:\\Users\\savan\\AppData\\Local\\Programs\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "     ---------------------------------------- 11.6/11.6 MB 9.5 MB/s eta 0:00:00\n",
      "Collecting seaborn\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "     -------------------------------------- 294.9/294.9 kB 4.6 MB/s eta 0:00:00\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.0-cp311-cp311-win_amd64.whl (8.0 MB)\n",
      "     ---------------------------------------- 8.0/8.0 MB 10.2 MB/s eta 0:00:00\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.0-cp311-cp311-win_amd64.whl (11.0 MB)\n",
      "     --------------------------------------- 11.0/11.0 MB 14.5 MB/s eta 0:00:00\n",
      "Collecting numpy\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "     --------------------------------------- 15.8/15.8 MB 14.5 MB/s eta 0:00:00\n",
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.3-py2.py3-none-any.whl (251 kB)\n",
      "     ------------------------------------- 251.3/251.3 kB 15.1 MB/s eta 0:00:00\n",
      "Collecting pipenv\n",
      "  Downloading pipenv-2023.12.1-py3-none-any.whl (3.1 MB)\n",
      "     ---------------------------------------- 3.1/3.1 MB 10.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\savan\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "     ------------------------------------- 505.5/505.5 kB 10.5 MB/s eta 0:00:00\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "     -------------------------------------- 345.4/345.4 kB 7.1 MB/s eta 0:00:00\n",
      "Collecting contourpy>=1.0.1\n",
      "  Downloading contourpy-1.2.1-cp311-cp311-win_amd64.whl (188 kB)\n",
      "     -------------------------------------- 188.2/188.2 kB 5.7 MB/s eta 0:00:00\n",
      "Collecting cycler>=0.10\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.52.4-cp311-cp311-win_amd64.whl (2.2 MB)\n",
      "     ---------------------------------------- 2.2/2.2 MB 10.0 MB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1\n",
      "  Downloading kiwisolver-1.4.5-cp311-cp311-win_amd64.whl (56 kB)\n",
      "     ---------------------------------------- 56.1/56.1 kB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\savan\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (24.0)\n",
      "Collecting pillow>=8\n",
      "  Downloading pillow-10.3.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 12.4 MB/s eta 0:00:00\n",
      "Collecting pyparsing>=2.3.1\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "     -------------------------------------- 103.2/103.2 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting scipy>=1.6.0\n",
      "  Downloading scipy-1.13.1-cp311-cp311-win_amd64.whl (46.2 MB)\n",
      "     --------------------------------------- 46.2/46.2 MB 11.7 MB/s eta 0:00:00\n",
      "Collecting joblib>=1.2.0\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "     ------------------------------------- 301.8/301.8 kB 18.2 MB/s eta 0:00:00\n",
      "Collecting threadpoolctl>=3.1.0\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Collecting et-xmlfile\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting certifi\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "     -------------------------------------- 163.8/163.8 kB 9.6 MB/s eta 0:00:00\n",
      "Collecting setuptools>=67\n",
      "  Downloading setuptools-70.0.0-py3-none-any.whl (863 kB)\n",
      "     ------------------------------------- 863.4/863.4 kB 13.5 MB/s eta 0:00:00\n",
      "Collecting virtualenv>=20.24.2\n",
      "  Downloading virtualenv-20.26.2-py3-none-any.whl (3.9 MB)\n",
      "     ---------------------------------------- 3.9/3.9 MB 15.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\savan\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Collecting distlib<1,>=0.3.7\n",
      "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
      "     ------------------------------------- 468.9/468.9 kB 14.8 MB/s eta 0:00:00\n",
      "Collecting filelock<4,>=3.12.2\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: platformdirs<5,>=3.9.1 in c:\\users\\savan\\appdata\\roaming\\python\\python311\\site-packages (from virtualenv>=20.24.2->pipenv) (4.2.2)\n",
      "Installing collected packages: pytz, distlib, tzdata, threadpoolctl, setuptools, pyparsing, pillow, numpy, kiwisolver, joblib, fonttools, filelock, et-xmlfile, cycler, certifi, virtualenv, scipy, pandas, openpyxl, contourpy, scikit-learn, pipenv, matplotlib, seaborn\n",
      "  Attempting uninstall: setuptools\n",
      "    Found existing installation: setuptools 65.5.0\n",
      "    Uninstalling setuptools-65.5.0:\n",
      "      Successfully uninstalled setuptools-65.5.0\n",
      "Successfully installed certifi-2024.2.2 contourpy-1.2.1 cycler-0.12.1 distlib-0.3.8 et-xmlfile-1.1.0 filelock-3.14.0 fonttools-4.52.4 joblib-1.4.2 kiwisolver-1.4.5 matplotlib-3.9.0 numpy-1.26.4 openpyxl-3.1.3 pandas-2.2.2 pillow-10.3.0 pipenv-2023.12.1 pyparsing-3.1.2 pytz-2024.1 scikit-learn-1.5.0 scipy-1.13.1 seaborn-0.13.2 setuptools-70.0.0 threadpoolctl-3.5.0 tzdata-2024.1 virtualenv-20.26.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Loading packages\n",
    "%pip install pandas seaborn matplotlib scikit-learn numpy openpyxl pipenv pycombat\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/01. Master_Latest data_Control clones_LP.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Retrieving data from excel file\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata/01. Master_Latest data_Control clones_LP.xlsx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m data_extracted_features \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_excel(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/01. Master_Latest data_Control clones_LP.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, usecols\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch number\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGenotype Neuron\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDiv calculated\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCulture treatment\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCapacitance\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput Resistance\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mResting membrane potential \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMaximum firing \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRheobase\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPSC freq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\savan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:495\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    494\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 495\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    505\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\savan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:1567\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m   1565\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[1;32m-> 1567\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\savan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:553\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    541\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    542\u001b[0m \u001b[38;5;124;03mReader using openpyxl engine.\u001b[39;00m\n\u001b[0;32m    543\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    550\u001b[0m \u001b[38;5;124;03m    Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[0;32m    551\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    552\u001b[0m import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenpyxl\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 553\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    554\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    555\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    556\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    557\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\savan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\excel\\_base.py:563\u001b[0m, in \u001b[0;36mBaseExcelReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[0;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m IOHandles(\n\u001b[0;32m    560\u001b[0m     handle\u001b[38;5;241m=\u001b[39mfilepath_or_buffer, compression\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmethod\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}\n\u001b[0;32m    561\u001b[0m )\n\u001b[0;32m    562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_or_buffer, (ExcelFile, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workbook_class)):\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_workbook_class):\n\u001b[0;32m    568\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbook \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\savan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[0;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/01. Master_Latest data_Control clones_LP.xlsx'"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel(\"01. Master_Latest data_Control clones_LP.xlsx\", engine='openpyxl')\n",
    "data_extracted_features = pd.read_excel(\"01. Master_Latest data_Control clones_LP.xlsx\", usecols=['Batch number', 'Genotype Neuron', 'Div calculated', 'Culture treatment', 'Capacitance', 'Input Resistance', 'Resting membrane potential ', 'Maximum firing ', 'Rheobase', 'EPSC freq'])\n",
    "\n",
    "print(data_extracted_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make GLM imputer work\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "import os\n",
    "\n",
    "# Assuming 'data_extracted_features' is your input dataframe\n",
    "data_extracted_features_impute_glm = data_extracted_features.copy()\n",
    "\n",
    "# Handle 'EPSC freq' values\n",
    "mask_glm = data_extracted_features_impute_glm['EPSC freq'].notna() & data_extracted_features_impute_glm['EPSC freq'].str.contains(\">\")\n",
    "data_extracted_features_impute_glm.loc[mask_glm, 'EPSC freq'] = np.nan\n",
    "\n",
    "# Convert 'EPSC freq' to numeric, setting errors='coerce' to handle any unexpected values\n",
    "data_extracted_features_impute_glm['EPSC freq'] = pd.to_numeric(data_extracted_features_impute_glm['EPSC freq'], errors='coerce')\n",
    "\n",
    "# Drop object columns for imputation\n",
    "object_columns_glm = data_extracted_features_impute_glm.select_dtypes(include=['object']).columns\n",
    "data_extracted_features_impute_glm_copy = data_extracted_features_impute_glm.drop(columns=object_columns_glm)\n",
    "\n",
    "# Set up the imputer with LinearRegression estimator\n",
    "imputer_glm = IterativeImputer(estimator=LinearRegression(), min_value=0,  random_state=0, max_iter=100)\n",
    "\n",
    "# Fit the imputer to your data and transform it\n",
    "data_extracted_features_imputed_glm = imputer_glm.fit_transform(data_extracted_features_impute_glm_copy)\n",
    "data_extracted_features_imputed_glm = pd.DataFrame(data_extracted_features_imputed_glm, columns=data_extracted_features_impute_glm_copy.columns)\n",
    "\n",
    "# Add back the object columns\n",
    "for column in object_columns_glm:\n",
    "    data_extracted_features_imputed_glm[column] = data_extracted_features_impute_glm[column]\n",
    "\n",
    "# Create dictioniary to store imputed values to be exported to Excel\n",
    "dict_imputed_glm_values = {\n",
    "    'Feature': [],\n",
    "    'Index': [],\n",
    "    'Original Value': [],\n",
    "    'Imputed Value': []\n",
    "}\n",
    "\n",
    "# Print imputed values for each column\n",
    "for column_glm in data_extracted_features_impute_glm_copy.columns:\n",
    "    missing_mask_column_glm = data_extracted_features_impute_glm_copy[column_glm].isnull()\n",
    "    imputed_missing_mask_column_glm = data_extracted_features_imputed_glm[column_glm].isnull()\n",
    "    imputed_values_mask_column_glm = missing_mask_column_glm & ~imputed_missing_mask_column_glm\n",
    "    imputed_values_column_glm = data_extracted_features_impute_glm_copy.loc[imputed_values_mask_column_glm, column_glm]\n",
    "    imputed_value_glm = data_extracted_features_imputed_glm.loc[imputed_values_mask_column_glm, column_glm]\n",
    "    if not imputed_values_column_glm.empty:\n",
    "        if not os.path.exists('run_1/qc/tables/GLM_imputation'):\n",
    "            os.makedirs('run_1/qc/tables/GLM_imputation')\n",
    "        imputed_value_pairs_glm = [(original_glm, imputed_glm) for original_glm, imputed_glm in zip(imputed_values_column_glm, imputed_value_glm)]\n",
    "        print(f\"Imputed values for {column_glm}:\")\n",
    "        formatted_output = \"\\n\".join([f\"Index: {index_glm + 2}\\nOriginal Value: {original_glm} --> Imputed value: {imputed_glm}\" for index_glm, (original_glm, imputed_glm) in zip(imputed_values_column_glm.index, imputed_value_pairs_glm)])\n",
    "        print(formatted_output + \"\\n\")\n",
    "        # Store imputed values in dictionary\n",
    "        indices_glm = imputed_values_mask_column_glm[imputed_values_mask_column_glm].index\n",
    "        dict_imputed_glm_values['Feature'].extend([column_glm] * len(indices_glm))\n",
    "        dict_imputed_glm_values['Index'].extend(indices_glm + 2)  # Adding 2 to match your index adjustment\n",
    "        dict_imputed_glm_values['Original Value'].extend(imputed_values_column_glm.fillna('nan').tolist())\n",
    "        dict_imputed_glm_values['Imputed Value'].extend(imputed_value_glm.tolist())\n",
    "        #print(dict_imputed_values)\n",
    "\n",
    "# Export imputed values to Excel\n",
    "imputed_df_glm = pd.DataFrame(dict_imputed_glm_values)  \n",
    "imputed_df_glm.to_csv(f\"run_1/qc/tables/GLM_imputation/GLM_imputed_values_0_FALSE_100.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This uses the MICE imputed dataset\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from pycombat import pycombat\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Make copy of data to not alter real data\n",
    "data_extracted_features_impute = data_extracted_features.copy()\n",
    "\n",
    "# Replace '>' values with NaN in 'EPSC freq' column\n",
    "mask = data_extracted_features_impute['EPSC freq'].notna() & data_extracted_features_impute['EPSC freq'].str.contains(\">\")\n",
    "data_extracted_features_impute.loc[mask, 'EPSC freq'] = np.nan\n",
    "\n",
    "# Convert 'EPSC freq' column to numeric\n",
    "data_extracted_features_impute['EPSC freq'] = pd.to_numeric(data_extracted_features_impute['EPSC freq'])\n",
    "\n",
    "#Define imputer\n",
    "imputer = IterativeImputer(random_state=0, min_value=0, sample_posterior=False, max_iter=100, tol=0.001)\n",
    "\n",
    "# Drop object columns for imputation. The columns which contain categorical values will be dropped for the MICE imputation to work.\n",
    "# These columns will be added back after imputation.\n",
    "object_columns = data_extracted_features_impute.select_dtypes(include=['object']).columns\n",
    "data_extracted_features_impute_copy = data_extracted_features_impute.drop(columns=object_columns)\n",
    "\n",
    "#Impute missing values\n",
    "data_extracted_features_imputed = imputer.fit_transform(data_extracted_features_impute_copy)\n",
    "data_extracted_features_imputed = pd.DataFrame(data_extracted_features_imputed, columns=data_extracted_features_impute_copy.columns)\n",
    "\n",
    "#Make another copy to not alter real data\n",
    "data_extracted_features_imputed_combat = data_extracted_features_imputed.copy()\n",
    "\n",
    "data_extracted_features_imputed_combat['Batch number'] = data_extracted_features_imputed_combat['Batch number'].astype(str)\n",
    "data_extracted_features_imputed_combat_categorical = data_extracted_features_imputed_combat.select_dtypes(include=['object'])\n",
    "data_extracted_features_imputed_combat_numeric = data_extracted_features_imputed_combat.select_dtypes(include=['float64', 'int64'])   \n",
    "\n",
    "#PyCombat doesn't use a pandas dataframe, but a numpy array.\n",
    "combat = pycombat.Combat()\n",
    "\n",
    "#These variables are used in SVM. The lines above make sure that the correct data is used\n",
    "data_extracted_features_imputed_combat_categorical = data_extracted_features_imputed_combat.select_dtypes(include=['object'])\n",
    "data_extracted_features_imputed_combat_numeric_transformed = combat.fit_transform(data_extracted_features_imputed_combat_numeric.to_numpy(), b=data_extracted_features_imputed_combat['Batch number']) \n",
    "data_extracted_features_imputed_combat_numeric_transformed = pd.DataFrame(data_extracted_features_imputed_combat_numeric_transformed, columns=data_extracted_features_imputed_combat_numeric.columns)\n",
    "\n",
    "data = data_extracted_features_imputed_combat_numeric_transformed.copy()\n",
    "\n",
    "# Separate features and target variable\n",
    "X = data.drop('Div calculated', axis=1)\n",
    "y = data['Div calculated']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# Random_state ensures that data is divided the same every time\n",
    "\n",
    "# Initialize StratifiedShuffleSplit\n",
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.1, random_state=42)\n",
    "\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "\n",
    "# Split the data\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    y_train = y_train.astype(int)\n",
    "    y_test = y_test.astype(int)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Accuracy: {accuracy:.2f}')\n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    print('Confusion Matrix:')\n",
    "    print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "    sns.heatmap(confusion_mat)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "# Check if the split is done correctly\n",
    "# print(\"Training Features Shape:\", X_train.shape)\n",
    "# print(\"Testing Features Shape:\", X_test.shape)\n",
    "# print(\"Training Target Shape:\", y_train.shape)\n",
    "# print(\"Testing Target Shape:\", y_test.shape)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
